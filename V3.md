## Computing the high water mark

Goal: For a given shard, establish a safe point to read to
without risking active transactions writing a smaller ULID.

To achieve this we'll utilize knowledge of SQL Server *sessions*.
Typically there's a smallish number of such sessions in total
(order of a 100). We make a table where such sessions *upsert*
themselves:
```sql
create table changefeed.last_write (
    object_id int not null,
    shard_id int not null,
    session_id int not null,  -- currently smallint, but being forwards compatible *shrug*
    primary key (object_id, shard_id),
    state tinyint not null,
    last_ulid binary(16)
)
```

### Invariants

1) A session will never write smaller ulids, only
newer ulids.
2) There will always be at least one session_id for each object_id/shard_id
   (.e.g, we may compact, but will always keep something there) in such
   a way that if you make a snapshot transaction, the head of the feed
   should equal the latest ulid with state=1 in the table.


**Note**: Sometimes session_ids are re-used, this can happen both
on the same SQL server process or after a failover. However, whatever
new process . The use of a session_id is simply to reduce `O(n)` entries
to `O(1)` entries; logically each write could have a row in the last_write
table without a session_id..

### State

The `state` can have values:
* 0 -- transaction pending
* 1 -- transaction committed
* 2 -- abandon

### Publisher steps

* Before the transaction *begins*, setup ULID generation by upserting
  to the `last_write` table with the generated ULID and also set
  `state=0`.
* Right before the transaction *commits*, set `state=1` on the session's
  row. However -- if that row has been set to `state=2` by another
  transaction, the transaction has to be aborted!

### Consumer steps

To establish a safe point to read to, the consumer has to scan through
`changefeed.last_write`.

* It cannot read past the lowest value with state=0.
* It can read until the highest value with state=1

If the consumer gets impatient it can "tombstone" a given session
(assume it has died) by writing `state=2`. Doing this will ensure
the publisher can't commit (if it follows the rules and listens to this).

Write locks on the `last_write` rows will potentially block the
consumer -- this *can* be mitigated if the publisher ensures that
the write to `last_write` and the `commit` happens in the same
network transaction (this requires custom transaction wrapping code
in the backend..)

So a better alternative may be issuing a `kill`. This also has race
conditions, sort of...

Perhaps a good use of a session application lock can help this...

--

Another issue here may be, what if we don't find anything in state=1.
This should be doable:

1) Reader *needs* to use snapshot isolation
2) Scan last_write to see if new data has arrived (state=1).
3) 
1) Read the values (i.e., get the max())
2) Do *not* use any values yet...
3) ...but scan last_write, and make sure to not read beyond any state=0
   values as they are a) signalled to be about to arrive, b) has
   not arrived yet. RACE RACE RACE: what if someone changed from 0 to 1
   between 1 and 3.

Snapshot isolation!

So:



